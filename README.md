# Towards web-native & GenAI-native data visualiztions

As the GenAI zeitgiest pushes forward one of the most interesting use cases that is emerging is the of data visualisation. The AI is becoming really good at interacting with the databases via tools and getting insights from the data and explaining them on the text however a lot of the time one just wants the AI to help one by generating a graph/chart or a data visualisation. 

This seems to be a trivial problem to solve however as one delves into this problem space the realisation hits that it is not a trivial problem and need a lot of engineering. There are a lot of edge cases and if one is building a chat application on web, mobile or desktop the Frontend and the chatbot backend intergration becomes a huge bottle neck. 

On the chatbot llm end one required the LLM to generate the graph defintion with all the data points. This in itself is a very interesting proiblem space however this artical concerns itself with the display/ rendering of these data visualisation.

## The current trend for GenAI data visualization: Ephemeral Applications

The major LLM providers including ChatGPT and Anthropic have come up with there general purpose appraoches to generating such data visualisation. On ChatGPT you can even do right now and ask the LLM to create a sample line chart and it will most probably create and render the visualisation. Notice that "most probably" was mentioned. This is due to the fact on how these provider and chat interfaces approach these kinds of tasks. 

These chatbot leverage a concept recently popularized as ephmeral applications. These are short lived and small code snippets which run in an execution environment. What these chatbots do is that internally they write statisitically domain specific language to code the visualisation on the fly, in our case this will most probably be python. However, python and even javascript code cannot run live on the application frontend (this is true even in case of Javascript code in a web appliucation as browsers don't allow any kind of cross-site scripts from executing as they are a very know OWASP 10 security vulnerablity)

Prior to GenAI, the community also wanted to run application in the browsers instead of downloading the code and running it locally. To solve this problem platforms like CodeSandbox were used and they are extremely good at their job. They take the software project, run a serverless-like container on the cloud, execute the code and provide the output.

ChatGPT and it competitors leverage the same kind of architecture to run these ephmeral appliucation. The llm generated the code and then internally a codesandbox like environment is created and the code is execute and the results are returned. 

The upside of this kind of application and why it make sense for OpenAI and compatitors to do this is that it allows the bots to be general. One can ask for any kind of code or thing and it will be code and run on the fly which is very useful. 

The downside of this is that this process is extremely unstable from a UX point of view. Most of the time, the code the AI generates is not correct or fails. This is especially the case when asking the chatbot to generate useful and meaning ful visualisations. Most of the times it is a hit an miss. 

Another bigger issue is that this kind of approach becomes extremely hard to develop and manage if similar feature are required in custom chatbot applications beind developed by developer individually or in an organisation. There are a lot of moving piece to architect, secure, deploy, run and maintain. And even if one gets all this right the biggest issue is that the code generated by AI might not even execute. 

One of the reasons, the AI is not able to generate correct code for the execution environemnt is because code by itself is very open-ended. There are many ways an AI can write code and most probably on every retry the code will be very very different. Also, the execution environment have their own constraints in terms of available packages and expected coding standard which the AI might not alway respect all these constraints. For engineers and developer a code that is buggy and renders in an error message is not that earth shattering. It is normal. However, for the majority of the non-technical stakeholders this is a very bad user experience and it drastically reduces the confidence in the application. 

If the use case requires the kind of generalisation (being able to build any application) mentioned above the rest of the article might not be helpful. However, if the mojority of the use case being built is for data visualisation then the rest of the article explore a very stable, simple and scalable approach



## A scalable contract for data visualisation 

In production grade applicatin for individual or enterprise most often there are 2 main components of the application. The backend and the frontend. In case of chatbot, the backend is usually a bunch of AI Agent with tools interacting with the overall enterprise eco-system. They make calls to the LLMs from providers and returns the final response strings or objects (depending on the API design). The agents in there are instructured to return the response in a specific formatted (which most often is Markdown or Executable Markdown (MDX)) string or a collection of objects with strings.


### Frontend visualisation components as GenAI tools

If ephemeral applications are an overkill one might decide to create frontend UI components (SwiftUi, ReactJS, etc) with a data interface and communicate that with the backend chatbot implementation so that the backend implemenrtation could take it as a tool and then generate the required data. The backend can immidiately stub the tool response as successful so that the AI knows the job is done and move on with the response. With this there is a statistically very high probabilityt that the data which is generated by the AI is correct and when it comes to the FE the FE component can render this. An a conceptual demonstartion of of such a repsosne payload will be 

```json
{
    messages: {
        role: 'assistant',
        content: [
            {
                type: 'text',
                content: 'Here is the line chart for the weather forcast for Sydney for the next 2 weeks.'
            },
            {
                type: 'line_chart',
                content: {
                    data: [
                        {time: 'Jan 24', temperature: 33},
                        {time: 'Feb 24', temperature: 32},
                        {time: 'Mar 24', temperature: 36},
                        {time: 'Apr 24', temperature: 39},
                    ],
                    x_axis_data_key: 'time' 
                }
            },
            {
                type: 'text',
                content: 'As a comparison of weather with Brisbane here is a bar chart'
            },
            {
                type: 'bar_chart',
                content: {
                    data: [
                        {time: 'Jan 24', Sydney: 33, Brisbane: 43},
                        {time: 'Feb 24', Sydney: 32, Brisbane: 23},
                        {time: 'Mar 24', Sydney: 36, Brisbane: 3},
                        {time: 'Apr 24', Sydney: 39, Brisbane: 13},
                    ],
                    x_axis_data_key: 'time' 
                }
            },
        ]
    }
}
```

The front and can go object by object and render the correct graphic according to the 'type' field. If a chart is not available then it can just display an error. The assumption of the system here is that there frontend and backend are both aware of the data contracts for the 'types'. 

This is a very nice approch to building stable data visualisations into the chatbot. The component which are rendering the visualisation are native to the appliucation frontend and will be full tested and stable. They will be 100% coherent to the chatbot theme which is also very nice. There is no extra code execution service eiter which save time, money and complixity

However, there are some major drawbacks of this approach. First, the final response is no longer a string rather a list of objects the logic for creation of this object can be tricky (depending on the implementation). Second, the backedn chatbot is now tightly coupled with frontend which will introduce massive tech debt as the application becomes more complicated. These, since these are tool calls and then these is data manipulation, the final chat message stored in the chat history will not have full context of the data and data sources etc. Moveover, there is an evolutionarty bottle neck. Today the charts on the frontend have a specific data contract but in future this might change. This will render the old chats stored in the database unrenderable which is not good. The developemnt will have to think about the backward compatimibiulty from the day one which is also a big and tricky investment. Also every new visualisation will require backend and frontend work.

> Going through the Cons of this approach make one want to go back to Ephemral application. But, there is another way which is much better

### Open source standard specification for data visualisation

The idea of the having data contracts between LLM and the application frontend is a valid one however the frontend components as GenAI tool is not very sustainable method. However, building on the above explored option this article would like to present a much better way using Vega JSON. Vega JSON is a very mature open source data visulisation spec/grammer which allows one to declare the structure and shape of the data visualisation in JSON format. It is a very robust spec, actively maintained, and allows one to perform basically any imaginable operation to create the visualisation. One declare the spec in JSON and a Vega renders (a render a per the Vega standards) takes this JSON and draws the visualisation. This spec is very well documented, used in data visualisation tools, very extremely expressive and above else a json string (which is the most web native thing). This schema can be generated programatically or throught GenAI as discussed further and since it is a standard spec it can run on any platform in which a Vega renderer is availble or one can create their own bespoke vega renderer. 

GenAI especially OpenAI and Anthropic model as very good at generating this JSON schema as the VEGA spec documentation has been available on the web since 2017 and it is very will documented so most of the AI models are very well able to generate this schema.


This apporach is extremely scalable as both the backend and frontend are cohesive (not coupled) and are coupled to an open standard schema which is a much better coupling place to be. (Remember, there is always some level of coupling in code what matter is how this coupling is managed well). As it will be explore future this appoarc does not require the response to be an object. It just requires that the repsonse must be a markdown string. This is also very customisable on the go you can as AI to generate any kind of visualisation no technical knowledge needed. This is stored in the chat history and since Vega is largly backwards compatibtle old chat will not break the visualisations (or you can also just pin to the latest vega version). You an import this visualisations in tools like Altire which are for data visulaisation. 

The downside of this is Vega only allows one to create the data visualisations meaning other kind of UIs like apps cannot be created. 

# React, Markdown, Vega & GenAI

This article explores the Vega-GenAI data visualisation approach in ReactJS. However, since this is a protable schema the vega renderer can be implemented for any language. 
